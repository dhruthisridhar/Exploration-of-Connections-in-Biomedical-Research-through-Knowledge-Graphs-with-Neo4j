{"cells":[{"cell_type":"markdown","id":"ef36baea-7d6f-4406-b3d8-fdcab865dc78","metadata":{"id":"ef36baea-7d6f-4406-b3d8-fdcab865dc78"},"source":["## Common imports and AWS setup"]},{"cell_type":"code","execution_count":null,"id":"c14f1518-308c-431c-b879-5707d2c666a0","metadata":{"id":"c14f1518-308c-431c-b879-5707d2c666a0"},"outputs":[],"source":["import dask.dataframe as dd\n","from dask.diagnostics import ProgressBar\n","from dotenv import dotenv_values\n","\n","env_v = dotenv_values(\".env\")\n","storage_opts = {'key': env_v[\"aws_access_key_id\"],\n","                'secret': env_v[\"aws_secret_access_key\"],\n","                'token': env_v[\"aws_session_token\"]}\n","\n","S3_URLS = {\n","    \"predication\" : \"s3://semdb-data/parquet/predication/\",\n","    \"sentence\": \"s3://semdb-data/parquet/sentence/\",\n","    \"entity\": \"s3://semdb-data/parquet/entity/\",\n","}\n","\n","# column labels for indexing. Found in schema desc.(https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR/dbinfo.html)\n","# types inferred from data.\n","CORRECTED_TYPES = {\n","    \"predication\": {\n","        \"PREDICATION_ID\": int,  # Auto-generated primary key for each unique predication\n","        \"SENTENCE_ID\": int,     # Foreign key to the SENTENCE table\n","        \"PMID\": int,            # The PubMed identifier of the citation to which the predication belongs\n","        \"PREDICATE\": str,       # The string representation of each predicate (for example TREATS, PROCESS_OF)\n","        \"SUBJECT_CUI\": str,     # The CUI of the subject of the predication\n","        \"SUBJECT_NAME\": str,    # The preferred name of the subject of the predication\n","        \"SUBJECT_SEMTYPE\": str, # The semantic type of the subject of the predication\n","        \"SUBJECT_NOVELTY\": int, # The novelty of the subject of the predication\n","        \"OBJECT_CUI\": str,      # The CUI of the object of the predication\n","        \"OBJECT_NAME\": str,     # The preferred name of the object of the predication\n","        \"OBJECT_SEMTYPE\": str,  # The semantic type of the object of the predication\n","        \"OBJECT_NOVELTY\": int,  # The novelty of the object of the predication\n","    },\n","    \"sentence\": {\n","        \"SENTENCE_ID\": int,               # Auto-generated primary key for each sentence\n","        \"PMID\": int,                      # The PubMed identifier of the citation to which the sentence belongs\n","        \"TYPE\": str,                      # 'ti' for the title of the citation, 'ab' for the abstract\n","        \"NUMBER\": int,                    # The location of the sentence within the title or abstract\n","        \"SENT_START_INDEX\": int,          # The character position within the text of the MEDLINE citation of the first character of the sentence  NEW\n","        \"SENT_END_INDEX\": int,            # The character position within the text of the MEDLINE citation of the last character of the sentence  NEW\n","        \"SENTENCE\": str,                  # The actual string or text of the sentence\n","    },\n","    \"entity\": {\n","        \"ENTITY_ID\": int,    # Auto-generated primary key for each unique entity\n","        \"SENTENCE_ID\": int,  # The foreign key to SENTENCE table\n","        \"CUI\": str,          # The CUI of the entity\n","        \"NAME\": str,         # The preferred name of the entity\n","        \"TYPE\": str,         # The semantic type of the entity\n","        \"TEXT\": str,         # The text in the utterance that maps to the entity\n","        \"START_INDEX\": int,  # The first character position (in document) of the text denoting the entity\n","        \"END_INDEX\": int,    # The last character position (in document) of the text denoting the entity\n","        \"SCORE\": int,        # The confidence score\n","    }\n","}\n","\n","# Some of these labels are not how they are described. This is due to a descrepancy between the Schema Version (v30)\n","# listed on the website as opposed to the current data version(v43)\n","CORRECTIONS = {\n","    \"sentence\": {\n","        \"drop\": [\n","            \"SENTENCE\", # Sentence is actually in the current \"SENT_END_INDEX\" column; label added back in correct position later.\n","                        # Whatever data is in this column is mostly (at least 189776747 rows) empty. No use in keeping.\n","            \"NORMALIZED_SECTION_HEADER\", # Again, mostly empty (at least 181859346 rows)\n","        ],\n","        \"rename\": {\n","            \"SENT_END_INDEX\" : \"SENTENCE\", # see above comment\n","            \"SECTION_HEADER\" : \"SENT_END_INDEX\", # infered from data.\n","        }\n","    },\n","    \"entity\": {\n","        \"drop\": [\n","            \"GENE_ID\", # Mostly empty\n","            \"GENE_NAME\", # Again, mostly empty\n","        ],\n","    },\n","}\n","\n","DATA = {\n","    \"predication\": None,\n","    \"sentence\": None,\n","    \"entity\": None,\n","}\n","\n"]},{"cell_type":"markdown","id":"7b33023d-a5e1-4e45-9e88-6e932afd6fd2","metadata":{"id":"7b33023d-a5e1-4e45-9e88-6e932afd6fd2"},"source":["## Clean and Upload Data As Necessary"]},{"cell_type":"code","execution_count":null,"id":"84734f3e-2992-4785-9cfd-ee56c4836863","metadata":{"id":"84734f3e-2992-4785-9cfd-ee56c4836863"},"outputs":[],"source":["def find_empty(data: dd) -> list[str]:\n","    \"\"\"Finds all columns with empty fields.\n","\n","    Args:\n","        data: a dask dataframe containing data.\n","\n","    Returns:\n","        A list of column names which contain empty fields for the given data.\n","    \"\"\"\n","    # calculate number of null values for each column\n","    missing_c = data.isnull().sum()\n","    with ProgressBar():\n","        missing = missing_c.compute()\n","\n","    # only keep columns with values > 0.\n","    cols = list(missing[missing > 0].index)\n","    return cols\n","\n","def fill_empty_fields(data:dd, corrected_cols: dict[str,type], cols_to_fill: list[str] ) -> dd:\n","    \"\"\"Fills all empty fields in dataframe.\n","\n","    Args:\n","        data: a dask dataframe containing data.\n","        corrected_cols: a dictionary containing the expected type of column.\n","        cols_to_fill: a list of column names which contain empty fields for the given data.\n","\n","    Returns:\n","        A new dataframe containing no empty fields.\n","    \"\"\"\n","\n","    for col in cols_to_fill:\n","        # fill field based on expected type.\n","        data = data.fillna({col: '-1' if corrected_cols[col] == int else \"Not available\"})\n","\n","    return data\n","\n","def correct_types(data:dd, corrected_cols: dict[str, type]) -> dd:\n","    \"\"\"Changes the datatype of all columns in dataframe.\n","\n","    Args:\n","        data: a dask dataframe without empty fields.\n","        corrected_cols: a dictionary containing the expected type of column.\n","\n","    Returns:\n","        A new dataframe with the new column datatypes.\n","    \"\"\"\n","\n","    for label, dtype in corrected_cols.items():\n","        data[label] = data[label].astype(dtype)\n","\n","    return data\n","\n","def drop_relabel_data(data:dd, corrections: dict) -> dd:\n","    \"\"\" Drops and relabels dataframe columns as specified.\n","\n","    Args:\n","        data: a dask dataframe containing data.\n","        corrections: a dictionary containing a list of the columns (by label) to drop\n","        and a dictionary specifying the labels to rename after the dropping operation.\n","\n","    Returns:\n","        A new dataframe with the corrections applied.\n","    \"\"\"\n","\n","    if corrections.get(\"drop\", False):\n","        data = data.drop(corrections[\"drop\"], axis=1)\n","\n","    if corrections.get(\"rename\", False):\n","        data = data.rename(columns= corrections[\"rename\"])\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"6a0e2c4a-ead1-4682-90a1-f629c680bfa5","metadata":{"id":"6a0e2c4a-ead1-4682-90a1-f629c680bfa5","outputId":"a22336fa-a613-465c-e2c8-aaacee2fd21b"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------PREDICATION--------------------\n","Action: Reading in data.\n","Action: Finding empty fields in data.\n","[########################################] | 100% Completed | 67.30 s\n","\n","Info: Empty fields in data: \n"," []\n","\n","Action: Filling empty fields in data.\n","Action: Converting data to expected datatypes.\n","Result: Success\n","\n","--------------------SENTENCE--------------------\n","Action: Reading in data.\n","Action: Dropping/Renaming Labels.\n","Action: Finding empty fields in data.\n","[########################################] | 100% Completed | 372.34 s\n","\n","Info: Empty fields in data: \n"," ['SENTENCE']\n","\n","Action: Filling empty fields in data.\n","Action: Converting data to expected datatypes.\n","Result: Success\n","\n","--------------------ENTITY--------------------\n","Action: Reading in data.\n","Action: Dropping/Renaming Labels.\n","Action: Finding empty fields in data.\n","[########################################] | 100% Completed | 13m 14s\n","\n","Info: Empty fields in data: \n"," ['ENTITY_ID', 'SENTENCE_ID', 'CUI', 'NAME', 'TYPE', 'TEXT', 'START_INDEX', 'END_INDEX', 'SCORE']\n","\n","Action: Filling empty fields in data.\n","Action: Converting data to expected datatypes.\n","Result: Success\n","\n"]}],"source":["for key, url in S3_URLS.items():\n","\n","    # read data into dataframe.\n","    print(f\"{'-' *20}{key.upper()}{'-' *20}\")\n","    print(f\"Action: Reading in data.\")\n","    try:\n","        DATA[key] = dd.read_parquet(url, storage_options=storage_opts)\n","    except Exception as e:\n","        print(f\"Result: Failed to read in data.\\n{e}\")\n","        continue\n","\n","    if CORRECTIONS.get(key, False):\n","        print(f\"Action: Dropping/Renaming Labels.\")\n","        try:\n","            DATA[key] = drop_relabel_data(DATA[key], CORRECTIONS[key])\n","        except Exception as e:\n","            print(f\"Result: Failed to drop or rename labels.\\n{e}\")\n","            continue\n","\n","    # get columns to fill.\n","    print(f\"Action: Finding empty fields in data.\")\n","    try:\n","        cols_to_fill = find_empty(DATA[key])\n","    except Exception as e:\n","        print(f\"Result: Failed to find empty fields in data.\\n{e}\")\n","        continue\n","\n","    print(f\"\\nInfo: Empty fields in data: \\n {cols_to_fill}\\n\")\n","\n","    # fill fields as necessary.\n","    print(f\"Action: Filling empty fields in data.\")\n","    try:\n","        DATA[key] = fill_empty_fields(DATA[key], CORRECTED_TYPES[key], cols_to_fill)\n","    except Exception as e:\n","        print(f\"Result: Failed to fill empty fields in data.\\n{e}\")\n","        continue\n","\n","    # convert datatypes as necessary.\n","    print(f\"Action: Converting data to expected datatypes.\")\n","    try:\n","        DATA[key] = correct_types(DATA[key], CORRECTED_TYPES[key])\n","    except Exception as e:\n","        print(f\"Result: Failed to clean and convert data.\\n{e}\")\n","        raise\n","\n","    print(f\"Result: Success\\n\")\n"]},{"cell_type":"markdown","id":"c414f066-7825-4c5d-b824-6370e51d0082","metadata":{"id":"c414f066-7825-4c5d-b824-6370e51d0082"},"source":["## Save Dataframe to S3 bucket as CSVs"]},{"cell_type":"code","execution_count":null,"id":"498e18a2-12c7-4970-83a1-b88d42cc9a49","metadata":{"id":"498e18a2-12c7-4970-83a1-b88d42cc9a49"},"outputs":[],"source":["s3_url = \"s3://semdb-data/parquet_cleaned/\"\n","def save_data(name: str):\n","    \"\"\"Uploads the data as a parquet file.\n","\n","    Args:\n","        name: the name of the dataframe.\n","    \"\"\"\n","    url = s3_url+name\n","    print(f\"{'-' *20}{name.upper()}{'-' *20}\")\n","    print(f\"Action: Saving data.\")\n","    try:\n","        with ProgressBar():\n","            DATA[name].to_parquet(url, storage_options=storage_opts, compression='gzip')\n","    except Exception as e:\n","        print(f\"Result: Failed to save data.\\n{e}\")\n","        return\n","\n","    print(f\"Result: Successfully saved data to {url}.\\n\")\n","    return"]},{"cell_type":"code","execution_count":null,"id":"3b5ac25d-75d3-43f1-a462-2b752c61f706","metadata":{"id":"3b5ac25d-75d3-43f1-a462-2b752c61f706","outputId":"c2fb4951-507e-453c-ad79-a5ab1729e39e"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------PREDICATION--------------------\n","Action: Saving data.\n","[########################################] | 100% Completed | 49m 32s\n","Result: Successfully saved data to s3://semdb-data/parquet_cleaned/predication.\n","\n"]}],"source":["save_data(\"predication\")"]},{"cell_type":"code","execution_count":null,"id":"f039df13-29b9-4051-9e37-ca2c67b38c50","metadata":{"id":"f039df13-29b9-4051-9e37-ca2c67b38c50","outputId":"93f83b69-8ef1-4c99-eea1-23d91e2d793c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------SENTENCE--------------------\n","Action: Saving data.\n","[########################################] | 100% Completed | 3hr 8ms\n","Result: Successfully saved data to s3://semdb-data/parquet_cleaned/sentence.\n","\n"]}],"source":["save_data(\"sentence\")"]},{"cell_type":"code","execution_count":null,"id":"d9314d92-a8e3-4e54-8084-4b772e4c243c","metadata":{"id":"d9314d92-a8e3-4e54-8084-4b772e4c243c"},"outputs":[],"source":["from pathlib import Path\n","import os\n","root = os.path.join(Path.cwd(), \"csv\")\n","ENTITY_FILE = os.path.join(root, \"entity\")\n","\n","try:\n","    DATA[\"entity\"] = dd.read_parquet(ENTITY_FILE)\n","except Exception as e:\n","    print(f\"Something seriously messed up happened.\\n{e}\")"]},{"cell_type":"code","execution_count":null,"id":"8d61c281-2d5d-4dca-a6c7-50f2bf39c61f","metadata":{"id":"8d61c281-2d5d-4dca-a6c7-50f2bf39c61f","outputId":"3dfb7dcb-ce4a-4bd8-8c6d-30140e63d8b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------ENTITY--------------------\n","Action: Saving data.\n","[########################################] | 100% Completed | 5hr 49m\n","Result: Successfully saved data to s3://semdb-data/parquet_cleaned/entity.\n","\n"]}],"source":["save_data(\"entity\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}