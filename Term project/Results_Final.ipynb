{"cells":[{"cell_type":"markdown","id":"0f863225-0aed-4452-b3e5-e236e188d92b","metadata":{"id":"0f863225-0aed-4452-b3e5-e236e188d92b"},"source":["# MAIN CODE"]},{"cell_type":"markdown","id":"b29fea99-d486-4109-8dc6-441c7034a3cd","metadata":{"id":"b29fea99-d486-4109-8dc6-441c7034a3cd"},"source":["## Constant Data\n","\n","This data should be well defined before running the program. It includes a host/port of the Neo4j Database to upload to as well as the locations, categories, and properties of the data.\n","\n","For our project, we've utilized AWS S3 buckets to store and share data. We also know the \"labels\" or what each value in our the various datasets represent so we list that along with there respective data types. The data types and labels will be instrumental in building a Cypher command to create a node for each data item with the appropriate properties."]},{"cell_type":"code","execution_count":null,"id":"604a9193-a3bc-42c0-b879-ed796ce42e67","metadata":{"id":"604a9193-a3bc-42c0-b879-ed796ce42e67"},"outputs":[],"source":["URI = \"bolt://localhost:7687\"\n","CATEGORIES = [\"predication\", \"sentence\", \"entity\"]\n","\n","\n","S3_URLS = {\n","    \"predication\" : \"s3://semdb-data/parquet_cleaned/predication/\",\n","    \"sentence\": \"s3://semdb-data/parquet_cleaned/sentence/\",\n","    \"entity\": \"s3://semdb-data/parquet_cleaned/entity/\",\n","}\n","\n","# column labels and data types as they appear in dataframes.\n","COL_LABELS = {\n","    \"predication\": list({\n","        \"PREDICATION_ID\": int,  # Auto-generated primary key for each unique predication\n","        \"SENTENCE_ID\": int,     # Foreign key to the SENTENCE table\n","        \"PMID\": int,            # The PubMed identifier of the citation to which the predication belongs\n","        \"PREDICATE\": str,       # The string representation of each predicate (for example TREATS, PROCESS_OF)\n","        \"SUBJECT_CUI\": str,     # The CUI of the subject of the predication\n","        \"SUBJECT_NAME\": str,    # The preferred name of the subject of the predication\n","        \"SUBJECT_SEMTYPE\": str, # The semantic type of the subject of the predication\n","        \"SUBJECT_NOVELTY\": int, # The novelty of the subject of the predication\n","        \"OBJECT_CUI\": str,      # The CUI of the object of the predication\n","        \"OBJECT_NAME\": str,     # The preferred name of the object of the predication\n","        \"OBJECT_SEMTYPE\": str,  # The semantic type of the object of the predication\n","        \"OBJECT_NOVELTY\": int,  # The novelty of the object of the predication\n","        }.items()),\n","    \"sentence\": list({\n","        \"SENTENCE_ID\": int,               # Auto-generated primary key for each sentence\n","        \"PMID\": int,                      # The PubMed identifier of the citation to which the sentence belongs\n","        \"TYPE\": str,                      # 'ti' for the title of the citation, 'ab' for the abstract\n","        \"NUMBER\": int,                    # The location of the sentence within the title or abstract\n","        \"SENT_START_INDEX\": int,          # The character position within the text of the MEDLINE citation of the first character of the sentence  NEW\n","        \"SENT_END_INDEX\": int,            # The character position within the text of the MEDLINE citation of the last character of the sentence  NEW\n","        \"SENTENCE\": str,                  # The actual string or text of the sentence\n","        }.items()),\n","    \"entity\": list({\n","        \"ENTITY_ID\": int,    # Auto-generated primary key for each unique entity\n","        \"SENTENCE_ID\": int,  # The foreign key to SENTENCE table\n","        \"CUI\": str,          # The CUI of the entity\n","        \"NAME\": str,         # The preferred name of the entity\n","        \"TYPE\": str,         # The semantic type of the entity\n","        \"TEXT\": str,         # The text in the utterance that maps to the entity\n","        \"START_INDEX\": int,  # The first character position (in document) of the text denoting the entity\n","        \"END_INDEX\": int,    # The last character position (in document) of the text denoting the entity\n","        \"SCORE\": int,        # The confidence score\n","        }.items()),\n","}"]},{"cell_type":"markdown","id":"afae9ac9-2fca-4438-8672-87b6ea4c794f","metadata":{"id":"afae9ac9-2fca-4438-8672-87b6ea4c794f"},"source":["## Authentication Setup\n","\n","The following section defines some basic functionality for retrieving authorization credentials to AWS and the Neo4j Database. The implementation is not important, but it allows us to avoid using hard-coded credentials."]},{"cell_type":"code","execution_count":null,"id":"41e3ed60-f68f-4499-8f37-3742bb4cc782","metadata":{"id":"41e3ed60-f68f-4499-8f37-3742bb4cc782"},"outputs":[],"source":["from dotenv import dotenv_values\n","\n","# get authentication credentials.\n","env_v = dotenv_values(\".env\")\n","storage_opts = {'key': env_v[\"aws_access_key_id\"],\n","                'secret': env_v[\"aws_secret_access_key\"],\n","                'token': env_v[\"aws_session_token\"],\n","               }\n","neo4j_auth = (env_v[\"neo4j_user\"], env_v[\"neo4j_pw\"])"]},{"cell_type":"markdown","id":"f9b9faf8-9ff3-478d-a9ec-333c18188dae","metadata":{"id":"f9b9faf8-9ff3-478d-a9ec-333c18188dae"},"source":["## Neo4j Database Connection\n","\n","The next section defines a series of functions to interact with the Neo4j database after authentication.\n","\n","In a typical distributed environment such as one created through the use of a Dask Cluster, connections to outside resources like the Neo4j `GraphDriver` object we utilize are not able to be shared across processes. This is typically because they contain a resource unique to a specific process (usually a thread lock or something similar). Because of this, the utility function `process_command` was created. While the process of creating a new connection and executing a single command introduces some overhead time costs, it is necessary to accomplish the project's long term goals."]},{"cell_type":"code","execution_count":null,"id":"c2e61648-cde3-4b71-b436-7bea6c681814","metadata":{"id":"c2e61648-cde3-4b71-b436-7bea6c681814"},"outputs":[],"source":["from neo4j import GraphDatabase, Result\n","\n","class GraphDriver:\n","    def __init__(self, uri):\n","        \"\"\"Creates an authorized API to neo4j server at uri.\n","\n","        Args:\n","            uri: the to the link and port to the neo4j server.\n","        \"\"\"\n","        self._driver = GraphDatabase.driver(uri, auth=neo4j_auth)\n","\n","    def execute_command(self, cmd:str)-> bool:\n","        \"\"\"Runs command on neo4j server.\n","\n","        Args:\n","            cmd: the Cypher-formatted command to run.\n","\n","        Returns:\n","            A boolean value specifiying wheter the command was executed successfully.\n","        \"\"\"\n","        res = True\n","\n","        if cmd == \"Failed\":\n","            return False\n","\n","        # Attempt command.\n","        try:\n","            with self._driver.session() as session:\n","                session.run(cmd)\n","        except:\n","            res = False\n","\n","        return res\n","\n","    def execute_command_with_results(self, cmd:str, t_function:str):\n","        \"\"\"Runs command on neo4j server and returns result.\n","\n","        Args:\n","            cmd: the Cypher-formatted command to run.\n","            t_function: the transformation function to run on result before returning\n","        Returns:\n","            An object created from running the transformation function on the result of the\n","            command.\n","\n","        Note:\n","            `t_function` parameter should be a member function of the neo4j.Result object.\n","        \"\"\"\n","        with self._driver.session() as session:\n","            return getattr(session.run(cmd), t_function)()\n","\n","    def delete_all_data(self):\n","        \"\"\"Deletes all nodes in database.\n","\n","        Warning:\n","            Do not use when database contains > 4 million nodes.\n","            May cause server to crash. Use the batch `delete_data`\n","            instead.\n","        \"\"\"\n","        self.execute_command(\"MATCH (n) DETACH DELETE n\")\n","\n","    def delete_data(self, batch_size:int, reps:int):\n","        \"\"\"Deletes all nodes in database by batches.\n","\n","        Args:\n","            batch_size: the number of nodes to delete.\n","            reps: the number of times to repeat the delete operation over\n","            {batch_size} nodes.\n","        \"\"\"\n","        cmd = f\"MATCH (n) WITH n LIMIT {batch_size} DETACH DELETE n\"\n","\n","        for n in range(reps):\n","            self.execute_command(cmd)\n","\n","    def close(self):\n","        \"\"\"Closing any open connections.\n","\n","        Note:\n","            Calling object is useless after calling this function.\n","        \"\"\"\n","        self._driver.close()\n","\n","def process_command(cmd:str, uri:str) -> bool:\n","    \"\"\"Creates connection to database and executes cmd.\n","\n","    Args:\n","        cmd: the Cypher-formatted command to run.\n","        uri: the to the link and port to the neo4j server.\n","    Returns:\n","        A boolean value specifiying wheter the command was executed successfully.\n","\n","    Note:\n","        Useful for dask df parallelizations since GraphDatabase objects can't be picked (serialized).\n","    \"\"\"\n","\n","    # create connection.\n","    driver = GraphDriver(uri)\n","\n","    # execute command and return result.\n","    return driver.execute_command(cmd)"]},{"cell_type":"markdown","id":"c31472a5-be47-42f2-8e9d-b9018d7fb6ec","metadata":{"id":"c31472a5-be47-42f2-8e9d-b9018d7fb6ec"},"source":["## Utility Functions\n","\n","These functions allow us to track the total time a function has taken to finish execution, create a simple log message, and abstract the creation of Cypher commands to query the Neo4j database."]},{"cell_type":"code","execution_count":null,"id":"5d83bdc2-9e77-4dde-beeb-8760595a150a","metadata":{"id":"5d83bdc2-9e77-4dde-beeb-8760595a150a"},"outputs":[],"source":["import time\n","import math\n","\n","def track_time(func):\n","    \"\"\"Records the elapsed time of the passed function.\n","\n","    Note:\n","        Only to be used as a decorator.\n","    \"\"\"\n","    def inner(*args, **kwargs):\n","        start = time.perf_counter()\n","\n","        # run passed function with all arguments. Capture any returned values.\n","        retval = func(*args, **kwargs)\n","\n","        print(f\"Elapsed time: {round(time.perf_counter() - start, 2)} seconds.\\n\")\n","\n","        return retval\n","\n","    return inner\n","\n","def log(msg:str) -> str:\n","    \"\"\"Print a message to console with timestamp.\n","\n","    Args:\n","        msg: the message to be displayed.\n","    Returns:\n","        A formatted string containing a timestamp and the passed message.\n","\n","    Note:\n","        Simple implementation instead of using the slightly more complex logging module.\n","    \"\"\"\n","\n","    return f\"{time.strftime('%H:%M:%S', time.localtime())}\\t{msg}\"\n","\n","def make_prop_string(label: str, val, dtype:type) -> str:\n","    \"\"\"Formats properties of Cypher Command.\n","\n","    Args:\n","        label: the label of the passed value.\n","        val: the integer or string data.\n","        dtype: the type of the passed value (i.e. int or str).\n","\n","    Returns:\n","        A string containing the property combo in the proper format.\n","    \"\"\"\n","    prop_string = \"\"\n","\n","    # add quotations around str values.\n","    if dtype == str:\n","        prop_string += f\"{label.lower()}:\\\"{val}\\\"\"\n","    else:\n","        prop_string+= f\"{label.lower()}:{val}\"\n","\n","    return prop_string\n","\n","def build_node_cmd(row, category:str, col_labels: list[tuple[str, type]]) -> str:\n","    \"\"\"Builds command to create a node with appropriate properties.\n","\n","    Args:\n","        row: the data extracted from a dataframe.\n","        category: the category of the data (i.e. \"predication\", \"entity\", or \"sentence\").\n","        col_labels: a list of tuples specifying the labels and data type of each value.\n","\n","    Returns:\n","        A string containing a properly formatted Cypher command.\n","    \"\"\"\n","    try:\n","        # create node properites in form \"prop:val, prop:val,...\"\n","        props = ', '.join([\n","            make_prop_string(label, row[label], dtype) for (label, dtype) in col_labels\n","        ])\n","\n","        cmd = f\"CREATE(:{category.capitalize()}{{{props}}})\"\n","\n","    # avoid crashing the program when command creation fails.\n","    except:\n","        cmd = \"Failed\"\n","    return cmd\n","\n","def build_relation_cmd(cat_one:str, cat_two:str, relation:str, batch_size:int=2500, props:str=\"\") -> str:\n","    \"\"\"Builds command to create relations between two node categories.\n","\n","    Args:\n","        cat_one: a string containing the category name to start the\n","        relation from.\n","        cat_two: a string containing the category name to direct the relation\n","        to.\n","        relation: a string containing the desired relation between\n","        the node categories.\n","        batch_size: the number of nodes to create a relation between. Defualts to 2500.\n","        props: a string containing a formatted list of properties to add to relation.\n","        Defaults to empty.\n","\n","    Returns:\n","            A string containing a properly formatted Cypher command.\n","    Note:\n","        Relationship is directed from category one Node to\n","        category two node based on matching \"sentence_id\" properties.\n","    \"\"\"\n","    # get all nodes of category one and two\n","    cmd = f\"MATCH (a:{cat_one.capitalize()}), (b:{cat_two.capitalize()}) \"\n","\n","    # match sentence IDd\n","    cmd+= \"WHERE a.sentence_id = b.sentence_id \"\n","\n","    # only get nodes that currently do not have the specified relation already\n","    cmd+= f\"AND NOT (a)-[:{relation}{{{props}}}]->(b) \"\n","\n","    cmd+= f\"WITH a, b LIMIT {batch_size} \"\n","\n","    # create relation\n","    cmd+= f\"MERGE (a)-[:{relation}{{{props}}}]->(b)\"\n","\n","    return cmd"]},{"cell_type":"markdown","id":"1fe679f4-e319-43eb-8058-87bece9cc128","metadata":{"id":"1fe679f4-e319-43eb-8058-87bece9cc128"},"source":["## Database Setup\n","\n","We start by initializing the driver (the connection to the database). As previously specified, the GraphDriver object has a plethora of methods to update the database with."]},{"cell_type":"code","execution_count":null,"id":"e61a42f2-8a73-4e55-962d-bb9f68815f7f","metadata":{"id":"e61a42f2-8a73-4e55-962d-bb9f68815f7f"},"outputs":[],"source":["# clear existing nodes.\n","driver = GraphDriver(URI)\n","driver.delete_all_data()\n","\n","# distributed\n","# driver.close()"]},{"cell_type":"markdown","id":"906f206c-015f-464a-8260-1e5ad9c546b3","metadata":{"id":"906f206c-015f-464a-8260-1e5ad9c546b3"},"source":["## Get Data From Buckets"]},{"cell_type":"code","execution_count":null,"id":"55f247ff-6315-4d2f-8de2-cc85c158a1c0","metadata":{"id":"55f247ff-6315-4d2f-8de2-cc85c158a1c0"},"outputs":[],"source":["import dask.dataframe as dd\n","data = {}\n","\n","for cat in CATEGORIES:\n","    # read data and store for later use.\n","    data[cat] = dd.read_parquet(S3_URLS[cat], storage_options=storage_opts)"]},{"cell_type":"markdown","id":"d016568e-8675-40ab-8974-c77bade8498d","metadata":{"id":"d016568e-8675-40ab-8974-c77bade8498d"},"source":["## Setup Distributed Environment\n","\n","While this section was not used during testing, it will be crucial to run the program across all of the available data as it's just too much for one client to handle."]},{"cell_type":"code","execution_count":null,"id":"206d62f7-a3b5-4c13-8611-498ac39a6642","metadata":{"id":"206d62f7-a3b5-4c13-8611-498ac39a6642"},"outputs":[],"source":["from dask.distributed import Client\n","\n","client_opts = {\n","    ## define options here such as schedule address, # workers, etc.\n","}\n","client = Client(**client_opts)\n","client"]},{"cell_type":"markdown","id":"0863edd5-3c4d-4b42-8cf3-6b0ea06ae883","metadata":{"id":"0863edd5-3c4d-4b42-8cf3-6b0ea06ae883"},"source":["## Command Creation and Execution\n","\n","It is not feasible to upload the entire dataset to a local Neo4j database. The local server will not be accessible to external clients and all of the data will need to eventually be uploaded to a dedicated server hosting the database. Instead, we aim to verifythe software to automate the process of node and relation creation functions as expected with a small subset of the real data.\n","\n","We'll utilize the first partition of each dataset to create and execute Cypher commands that create nodes and the relations between each type of node. After each step, we'll verify our results."]},{"cell_type":"code","execution_count":null,"id":"58419ba6-f0cc-4801-99b1-b3a2a1a9590d","metadata":{"id":"58419ba6-f0cc-4801-99b1-b3a2a1a9590d"},"outputs":[],"source":["@track_time\n","def create_nodes(cat):\n","    \"\"\"Creates and Executes Node Creation Commands for Dataframe based on category.\n","\n","    Args:\n","        cat: the category of the dataframe (i.e. \"predication\", \"entity\", or \"sentence\").\n","\n","    Note:\n","        All commands are attempted regardless of previous failure.\n","    \"\"\"\n","\n","    print(f\"\\n{'-' *30}{cat.upper()}{'-' *30}\")\n","\n","    # create commands using dask optimizations.\n","    print(f\"\\t{log('Building commands...')} \")\n","\n","    # only take rows whose \"Sentence ID\" column wasn't null during cleaning.\n","    cmds = (\n","        data[cat][data[cat][\"SENTENCE_ID\"] != -1].apply(\n","            build_node_cmd, axis=1, category=cat, col_labels=COL_LABELS[cat], meta=('cypher_cmds', 'str')\n","        ).persist()\n","    )\n","\n","    # cmds = data[cat].apply(build_node_cmd, axis=1, category=cat, col_labels=COL_LABELS[cat], meta=('cypher_cmds', 'str')).persist()\n","\n","    print(f\"\\t{log('Command building complete.')} \")\n","\n","    print(f\"\\t{log('Attempting to execute commands...')} \")\n","\n","    # non-distributed\n","    res = cmds.apply(driver.execute_command, meta=('execution_res', 'bool')).persist()\n","\n","    # distributed.\n","    # res = client.persist(cmds.apply(process_command, uri=URI, meta=('execution_res', 'bool')))\n","\n","    print(f\"\\t{log('Command execution complete.')} \")\n","\n","    print(f\"\\nFailed Command Creations: {cmds[cmds=='Failed'].count().compute()}\")\n","    print(f\"Failed Command Executions: {res[res==False].count().compute()}\")\n","\n","    return\n","\n","@track_time\n","def create_relations(relation_name:str, cat_one:str, cat_two:str, relation:str, batch_size:int, reps:int):\n","    \"\"\"Creates and Executes Node Relation Commands based on passed relation values.\n","\n","    Args:\n","        cat_one: a string containing the category name to start the relation from.\n","        cat_two: a string containing the category name to direct the relation to.\n","        relation: a string containing the desired relation between the node categories.\n","        batch_size: the number of nodes to to create a relation between in one cmd.\n","    \"\"\"\n","\n","    # create new database connection.\n","    # driver = GraphDriver(URI)\n","\n","\n","    execution_failures = 0\n","    print(f\"\\n{'-'*30}{relation_name} Relation{'-'*30}\")\n","\n","    print(f\"\\t{log('Building command...')} \")\n","    # attempt to create command.\n","    try:\n","        cmd = build_relation_cmd(cat_one, cat_two, relation, batch_size )\n","    except Exception as e:\n","        print(f\"\\t{log('Failed to build command. Exiting.')} \")\n","        return\n","\n","    # attempt to run command.\n","    print(f\"\\t{log('Attempting to execute commands...')} \")\n","    for i in range(reps):\n","        if not (driver.execute_command(cmd)):\n","            execution_failures+=1\n","\n","    print(f\"\\t{log(f'Failed Command Executions: {execution_failures}')}\")\n","\n","    # driver.close()\n","\n","    return\n","\n","relation_cmds = {\n","    \"Predication -> Sentence\": {\n","        \"category_one\": \"predication\",\n","        \"category_two\": \"sentence\",\n","        \"relation\": \"PREDICATE_OF\",\n","    },\n","    \"Predication -> Entity\": {\n","        \"category_one\": \"predication\",\n","        \"category_two\": \"entity\",\n","        \"relation\": \"PREDICATES\",\n","    },\n","    \"Entity -> Sentence\": {\n","        \"category_one\": \"entity\",\n","        \"category_two\": \"sentence\",\n","        \"relation\": \"SUBJECT_OF\",\n","    },\n","}"]},{"cell_type":"code","execution_count":null,"id":"b7fb1c75-d467-48e3-81ad-9f0944c2178c","metadata":{"id":"b7fb1c75-d467-48e3-81ad-9f0944c2178c","outputId":"cee8d7bf-16ab-4433-bdc7-b4ac0b9f3d0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------PREDICATION------------------------------\n","\t21:20:10\tBuilding commands... \n","\t21:20:15\tCommand building complete. \n","\t21:20:15\tAttempting to execute commands... \n","\t22:32:32\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4341.93 seconds.\n","\n","\n","------------------------------SENTENCE------------------------------\n","\t22:32:32\tBuilding commands... \n","\t22:32:35\tCommand building complete. \n","\t22:32:35\tAttempting to execute commands... \n","\t23:29:55\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 3443.85 seconds.\n","\n","\n","------------------------------ENTITY------------------------------\n","\t23:29:55\tBuilding commands... \n","\t23:30:01\tCommand building complete. \n","\t23:30:01\tAttempting to execute commands... \n","\t00:58:40\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 1386\n","Elapsed time: 5324.15 seconds.\n","\n"]}],"source":["# run code on small portion of dataset.\n","for cat in CATEGORIES:\n","    data[cat] = data[cat].partitions[0]\n","\n","# create and execute commands to create nodes for each dataframe.\n","for cat in CATEGORIES:\n","    create_nodes(cat)"]},{"cell_type":"markdown","id":"4b2d57f3-b1e6-4fa2-a969-1db791d4d5d3","metadata":{"id":"4b2d57f3-b1e6-4fa2-a969-1db791d4d5d3"},"source":["## Results of Node Creation\n","\n","In order, a subset (25) of the created predication, sentence, and entity nodes are shown. Each node category has roughly 400,000 nodes."]},{"cell_type":"code","execution_count":null,"id":"90cd110a-9a3d-451b-8e66-fd7693abd4a1","metadata":{"id":"90cd110a-9a3d-451b-8e66-fd7693abd4a1","outputId":"1202f462-5c1f-4571-fc55-7deea0722139"},"outputs":[{"data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1S1kQSC7eJ2WOghXqorkvoBu19_QnJGGV/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1S1kQSC7eJ2WOghXqorkvoBu19_QnJGGV/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]},{"cell_type":"code","execution_count":null,"id":"6ae0539e-882e-4b52-9e55-79bf7da1a791","metadata":{"id":"6ae0539e-882e-4b52-9e55-79bf7da1a791","outputId":"02748091-d09a-4e86-98fd-7a0b18211cc5"},"outputs":[{"data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/18cXuOOekhR7AI_zMXfr_QGw0ndzv0boB/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/18cXuOOekhR7AI_zMXfr_QGw0ndzv0boB/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]},{"cell_type":"code","execution_count":null,"id":"55d83d9e-725f-4404-b478-10c88388ccd8","metadata":{"id":"55d83d9e-725f-4404-b478-10c88388ccd8","outputId":"d0ccc3b6-7e90-4f92-ebf8-e39b71b8a70e"},"outputs":[{"data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1F98A49WhvydMs5XbNKUEGf4Wj2ZiNnig/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1F98A49WhvydMs5XbNKUEGf4Wj2ZiNnig/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]},{"cell_type":"code","execution_count":null,"id":"04c54190-ed26-4a6b-96d3-dc85a6044835","metadata":{"id":"04c54190-ed26-4a6b-96d3-dc85a6044835","outputId":"18e7d583-7f2a-4782-e7bf-2f15ea2ddd0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------Predication -> Sentence Relation------------------------------\n","\t01:44:05\tBuilding command... \n","\t01:44:05\tAttempting to execute commands... \n","\t01:44:49\tFailed Command Executions: 0\n","Elapsed time: 44.19 seconds.\n","\n","\n","------------------------------Predication -> Entity Relation------------------------------\n","\t01:44:49\tBuilding command... \n","\t01:44:49\tAttempting to execute commands... \n","\t01:45:43\tFailed Command Executions: 0\n","Elapsed time: 54.52 seconds.\n","\n","\n","------------------------------Entity -> Sentence Relation------------------------------\n","\t01:45:43\tBuilding command... \n","\t01:45:43\tAttempting to execute commands... \n","\t01:46:26\tFailed Command Executions: 0\n","Elapsed time: 43.17 seconds.\n","\n"]}],"source":["# create and execute commands to make relationships between nodes in database.\n","batch_size = 3500\n","expected_nodes = 400000\n","for key, value in relation_cmds.items():\n","\n","    create_relations(key, value[\"category_one\"], value[\"category_two\"], value[\"relation\"], batch_size, math.ceil(expected_nodes/batch_size))"]},{"cell_type":"markdown","id":"9743fd50-6c64-4759-90fd-0eda8a65cf0e","metadata":{"id":"9743fd50-6c64-4759-90fd-0eda8a65cf0e"},"source":["## Results of Relation Creation\n","\n","In the image below, a query which finds nodes with matching sentence IDs is executed. Just like any other resource intensive query, the results are limited to avoid potentially crashing the server.\n","\n","As expected, mutliple entities relate to a single predicate(predication node), which relate to a single sentence. This is because there are roughly 15x more entities than predications and 8x more entities than sentences indicating a one-to-many relationship between entities and sentences/predications."]},{"cell_type":"code","execution_count":3,"id":"4be491d2-6966-453c-9b2f-a0863340f861","metadata":{"id":"4be491d2-6966-453c-9b2f-a0863340f861","outputId":"f86a5143-b276-4b64-f8ef-dde3f41efea3","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1701563747638,"user_tz":300,"elapsed":194,"user":{"displayName":"Malakai Spann","userId":"02615893032647026168"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<iframe src=\"https://drive.google.com/file/d/1qRpJWaNN17LgcY_mQ3umNslTQeegFy3J/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"]},"metadata":{}}],"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1qRpJWaNN17LgcY_mQ3umNslTQeegFy3J/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]},{"cell_type":"markdown","id":"da30a950-0a92-4572-90d5-d93ddd1beb58","metadata":{"id":"da30a950-0a92-4572-90d5-d93ddd1beb58"},"source":["## Complex Operations\n","\n","In the following section, we'll experiment with some features we can use with the Neo4j database.\n","\n","First, we query all available predication nodes to gather a list of unique subject semantic types. Next, we select two semantic types and construct a query that returns all nodes ( predication, sentence, and entity\") that connect to a single sentence. For this to work, we needed to do some background work and inspect the database for sets of predication nodes that connected to a single sentence node. Since the entity nodes have a \"many-to-one\" relation with both predication and sentence nodes, where \"many\" is an understatement, and predication nodes have more of a \"some-to-one\" relation with the sentence nodes, we focused on the predication nodes. The semantic types \"menp,\" which stands for \"Mental Process,\" and \"hlca,\" which stands for \"Health Care Activity,\" were two suitable candidates.\n","\n","Finally, we construct and execute a query that returns all nodes related to the same sentence and connected to predications nodes with a subject semantic type of \"menp\" or \"hlca.\"\n","\n","The result was a single interconnected graph where all entity nodes connected to the sentence node via an \"ENTITY_OF\" relation, all predication nodes connected to the sentence node via a \"PREDICATION_OF\" relation,  and all predication nodes connected to all entity nodes via a \"PREDICATES\" relation.\n"]},{"cell_type":"code","execution_count":null,"id":"b111f80d-cbca-4b3a-ad10-80647a0504b6","metadata":{"id":"b111f80d-cbca-4b3a-ad10-80647a0504b6","outputId":"6858303b-4b55-48f6-ee8b-cf3d28b7b2b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["virs\n","dsyn\n","mamm\n","bacs\n","aapp\n","gngm\n","bact\n","phsu\n","celc\n","inch\n","anim\n","topp\n","antb\n","medd\n","inbe\n","fndg\n","sosy\n","hlca\n","lbpr\n","orch\n","inpo\n","genf\n","emst\n","bpoc\n","cell\n","phsf\n","tisu\n","enzy\n","chem\n","patf\n","neop\n","horm\n","nusq\n","imft\n","orgf\n","mobd\n","menp\n","bdsu\n","podg\n","moft\n","spco\n","diap\n","nnon\n","blor\n","hcro\n","prog\n","ortf\n","resa\n","celf\n","comd\n","bsoj\n","cgab\n","acab\n","orga\n","humn\n","popg\n","lipd\n","carb\n","elii\n","vita\n","mbrt\n","irda\n","npop\n","aggp\n","orgt\n","chvf\n","plnt\n","hops\n","phpr\n","emod\n","fngs\n","invt\n","arch\n","chvs\n","alga\n","socb\n","food\n","sbst\n","rcpt\n","nsba\n","bdsy\n","grup\n","orgm\n","vtbt\n","bodm\n","eico\n","strd\n","anst\n","mnob\n","anab\n","biof\n","fish\n","dora\n","opco\n","geoa\n","bird\n","qnco\n","pros\n","clnd\n","rnlw\n","edac\n","clna\n","famg\n","lbtr\n","eehu\n","rept\n","amph\n","bmod\n","ocac\n","resd\n","ffas\n","mcha\n","shro\n","rich\n","ocdi\n","acty\n","hcpp\n","amas\n","gora\n","bhvr\n","phob\n"]}],"source":["# find all unique subject semtypes among available predication nodes.\n","cmd = \"MATCH (p:Predication) WITH DISTINCT p.subject_semtype as distinct_subject_types RETURN collect(distinct_subject_types)\"\n","\n","# result is a 3D array of strings in this case.\n","# See documentation here: https://neo4j.com/docs/api/python-driver/current/api.html#neo4j.Result.values\n","unique_semtypes = driver.execute_command_with_results(cmd, \"values\")\n","print(*unique_semtypes[0][0], sep = \"\\n\")"]},{"cell_type":"code","execution_count":null,"id":"6e074bbe-f6a2-4449-8402-af0d69c65ac2","metadata":{"id":"6e074bbe-f6a2-4449-8402-af0d69c65ac2","outputId":"25d42e37-5235-4cb2-a831-9d1651fecc0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["MATCH (s:Sentence), (e:Entity), (`p0`:Predication), (`p1`:Predication)\n","WHERE (\n","(s.sentence_id = e.sentence_id AND `p0`.sentence_id = `p1`.sentence_id AND `p1`.sentence_id = s.sentence_id)\n","AND (`p0`.subject_semtype = 'menp' AND `p1`.subject_semtype = 'hlca')\n",")\n","MATCH (`p0`)-[`r0`]->(s) \n","MATCH (`p0`)-[`r1`]->(e) \n","MATCH (`p0`)-[`r2`]->(s) \n","MATCH (`p1`)-[`r3`]->(s) \n","MATCH (`p1`)-[`r4`]->(e) \n","MATCH (`p1`)-[`r5`]->(s) \n","RETURN s, e, collect(distinct `r0`), collect(distinct `r1`), collect(distinct `r2`), collect(distinct `r3`), collect(distinct `r4`), collect(distinct `r5`), `p0`, `p1`\n","LIMIT 100\n"]}],"source":["# extracted from list above\n","# full semantic type descriptions can be found here: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt\n","semtypes = [\n","    \"menp\", # Mental Process\n","    \"hlca\" # Health Care Activity\n","]\n","\n","# create ids to separate each semtype. Will be of form `p0`, `p1`, ...\n","ids = [f\"`p{i}`\" for i in range(len(semtypes))]\n","\n","# define all variables in query\n","cmd = \"MATCH (s:Sentence), (e:Entity), \"\n","# iterate over `pX` ids and add to variable definitions.\n","cmd += (\", \".join([f\"({id}:Predication)\" for id in ids]) + \"\\n\")\n","\n","\n","# ensure all sentence ids match. In other words, all nodes should connect to a single sentence.\n","cmd += \"WHERE (\\n(s.sentence_id = e.sentence_id AND \"\n","\n","# ensure each predication variable's sentence id matches the sentence id.\n","# Final format `pX`.sentence_id = `pX+1`.sentence_id AND ... `pN`.sentence_id = s.sentence_id\n","cmd += (\n","    \" AND \".join(\n","        [f\"{ids[i]}.sentence_id = {ids[i+1]}.sentence_id\" if i != len(ids)-1 else f\"{ids[i]}.sentence_id = s.sentence_id\" for i in range(len(ids))]\n","    ) + \")\\n\"\n",")\n","\n","# match all semtypes in list\n","cmd += (\n","    \"AND (\"\n","    + \" AND \".join([f\"{id}.subject_semtype = '{semtype}'\" for id, semtype in zip(ids ,semtypes)])\n","    + \")\\n)\\n\"\n","    )\n","\n","\n","def get_relations(id:str, pos:int) -> str:\n","    \"\"\"Retrieves the relations for a predication node.\n","\n","    Args:\n","        id: the variable identifier for the predication node.\n","        pos: the position of the variable identifier in relation to the others.\n","\n","    Returns:\n","        A portion of a cypher command which limits results only to Nodes that have\n","        a relation to another category of node.\n","    \"\"\"\n","    start = pos*3\n","\n","    string = f\"MATCH ({id})-[`r{start}`]->(s) \\n\"\n","    string += f\"MATCH ({id})-[`r{start+1}`]->(e) \\n\"\n","    string += f\"MATCH ({id})-[`r{start+2}`]->(s) \\n\"\n","\n","    return string\n","\n","# ensure only nodes with relations are returned.\n","# Many nodes will not have relations because we are only working with a portion of the data.\n","cmd += \"\".join([get_relations(id, i) for i, id in enumerate(ids)])\n","\n","# limit to 100 Results.\n","cmd += \"RETURN s, e, \"\n","cmd += (\n","    \", \".join([f\"collect(distinct `r{i}`)\" for i in range(len(ids)*3)])\n","    + \", \"\n",")\n","cmd += (\n","    \", \".join(ids)\n","    + \"\\n\"\n",")\n","cmd += \"LIMIT 100\"\n","\n","print(cmd)"]},{"cell_type":"code","execution_count":null,"id":"3f4ee585-035f-4ece-9f83-61965d2a3807","metadata":{"id":"3f4ee585-035f-4ece-9f83-61965d2a3807","outputId":"eff6c245-5322-4eb5-c819-7e06176f4078"},"outputs":[{"name":"stdout","output_type":"stream","text":["166 ms ± 54.7 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","driver.execute_command_with_results(cmd, \"graph\")"]},{"cell_type":"markdown","id":"c1d54d9c-a485-4fc7-9779-650400593cab","metadata":{"id":"c1d54d9c-a485-4fc7-9779-650400593cab"},"source":["**NOTE: The following cell will not display properly unless the code has been executed. Please see the next cell for a static image of the of the cmd result.**"]},{"cell_type":"code","execution_count":null,"id":"2cc8bc7b-7046-4b6a-90d7-81394c60000e","metadata":{"id":"2cc8bc7b-7046-4b6a-90d7-81394c60000e","outputId":"9482ef09-52de-49f4-8d6b-f5ca96475170","colab":{"referenced_widgets":["f7db05784f2c495f9d0b16719a939b10"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7db05784f2c495f9d0b16719a939b10","version_major":2,"version_minor":0},"text/plain":["GraphWidget(layout=Layout(height='500px', width='100%'))"]},"metadata":{},"output_type":"display_data"}],"source":["from yfiles_jupyter_graphs import GraphWidget\n","\n","w = GraphWidget(graph=driver.execute_command_with_results(cmd, \"graph\"))\n","w.show()"]},{"cell_type":"code","execution_count":null,"id":"6076dd97-d863-4dcf-beaa-c59ca0b78206","metadata":{"id":"6076dd97-d863-4dcf-beaa-c59ca0b78206","outputId":"a313ccf6-8261-4fce-8cdf-355eee12602d"},"outputs":[{"data":{"text/html":["\n","<iframe src=\"https://drive.google.com/file/d/1ipRIVbZKerwQPuMCJhhrj7OO8Fn0U50x/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","\n","<iframe src=\"https://drive.google.com/file/d/1ipRIVbZKerwQPuMCJhhrj7OO8Fn0U50x/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]},{"cell_type":"markdown","id":"9693938c-e5b5-4dc1-9390-e54d4bc190e4","metadata":{"id":"9693938c-e5b5-4dc1-9390-e54d4bc190e4"},"source":["# Performance Testing"]},{"cell_type":"markdown","id":"a53b0201-03c0-4c7e-bf26-b35f75a5046a","metadata":{"id":"a53b0201-03c0-4c7e-bf26-b35f75a5046a"},"source":["Below are the same functions utilized in the main portion of the code with some slight alterations to make them work using the itertuples method. There are no significant changes that will affect performance of the test."]},{"cell_type":"code","execution_count":null,"id":"22a8fd16-7499-42d5-abbc-b7c85261f867","metadata":{"id":"22a8fd16-7499-42d5-abbc-b7c85261f867"},"outputs":[],"source":["def build_node_cmd_by_itertuples(row, category:str, col_labels: list[tuple[str, type]]) -> str:\n","    \"\"\"Builds command to create a node with appropriate properties.\n","\n","    Args:\n","        row: the data extracted from a dataframe.\n","        category: the category of the data (i.e. \"predication\", \"entity\", or \"sentence\").\n","        col_labels: a list of tuples specifying the labels and data type of each value.\n","\n","    Returns:\n","        A string containing a properly formatted Cypher command.\n","    \"\"\"\n","    try:\n","        # create node properites in form \"prop:val, prop:val,...\"\n","\n","        # note, used integer-based indexing rather than label-based indexing.\n","        props = ''.join([\n","            make_prop_string(label, row[i], dtype, False) if label != col_labels[-1][0]\n","                else make_prop_string(label, row[i], dtype, True) for i, (label, dtype) in enumerate(col_labels)\n","        ])\n","\n","        cmd = f\"CREATE(:{category.capitalize()}{{{props}}})\"\n","\n","    # avoid crashing the program when command creation fails.\n","    except:\n","        cmd = \"Failed\"\n","    return cmd\n","\n","@track_time\n","def create_nodes_by_itertuples(cat):\n","    \"\"\"Creates and Executes Node Creation Commands for Dataframe based on category.\n","\n","    Args:\n","        cat: the category of the dataframe (i.e. \"predication\", \"entity\", or \"sentence\").\n","\n","    Note:\n","        All commands are attempted regardless of previous failure.\n","    \"\"\"\n","\n","    # distributed\n","    # driver = GraphDriver(URI)\n","\n","    # note, added failure checking during each loop instead of at the end.\n","    failures = {\n","        \"creation\" : 0,\n","        \"execution\" : 0\n","    }\n","\n","    print(f\"\\n{'-' *30}{cat.upper()}{'-' *30}\")\n","\n","    # create commands using dask optimizations.\n","    print(f\"\\t{log('Building and executing commands...')} \")\n","\n","    for row in data[cat].itertuples():\n","        cmd = build_node_cmd_by_itertuples(row[1:],category=cat, col_labels=COL_LABELS[cat])\n","\n","        if cmd == \"Failed\":\n","            failures[\"creation\"] += 1\n","\n","        if not (driver.execute_command(cmd)):\n","            failures[\"execution\"] += 1\n","\n","    print(f\"\\t{log('Build and execution completed.')} \")\n","\n","    print(f\"\\nFailed Command Creations: {failures['creation']}\")\n","    print(f\"Failed Command Executions: {failures['execution']}\")\n","\n","    # distributed\n","    # driver.close()\n","\n","    return"]},{"cell_type":"markdown","id":"d90b0b06-1bfe-4154-b837-0a99299bdf0c","metadata":{"id":"d90b0b06-1bfe-4154-b837-0a99299bdf0c"},"source":["Summary: There are three main bottlenecks during the process. The creation of the commands for all rows (somewhat time consuming), executing each command on the neo4j server (very, very, very time consuming), and creating the relations between the nodes after the uploads(tba).\n","\n","Generally, the faster we can iterate over some data, whether it be all rows in the dataframe to extract the data to build commands or over a series of commands, the faster a process will go. In the test below, a small portion(~12 MB) of real data is iterated over using two different methods: the [apply](https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.apply.html) method and the [itertuples](https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.itertuples.html) method. Each set of tests is ran 3 times to calculate an average time as performace can vary slightly between runs. The data is stored in a single file.\n","\n","First, we test command building. The results are below.\n","\n","_Note_:\n","\n","- The following tests were executed independently of the other sections of this file.\n"]},{"cell_type":"code","execution_count":null,"id":"0ac302e1-4798-494b-b045-435e53efa82b","metadata":{"id":"0ac302e1-4798-494b-b045-435e53efa82b"},"outputs":[],"source":["t_cat = \"predication\"\n","temp = \"predication_full\"\n","@track_time\n","def test_build_by_apply(cat):\n","    cmds = data[cat].apply(build_node_cmd, axis=1, category=cat, col_labels=COL_LABELS[cat], meta=('cypher_cmds', 'str')).persist()\n","\n","\n","@track_time\n","def test_build_by_itertuples(cat):\n","    for row in data[cat].itertuples():\n","        cmd = build_node_cmd_by_itertuples(row[1:],category=cat, col_labels=COL_LABELS[cat])\n","\n","# save full full dataframe in temp location.\n","data[temp] = data[t_cat]\n","\n","# 1 partition roughly = 12 MB.\n","data[t_cat] = data[temp].partitions[0]"]},{"cell_type":"code","execution_count":null,"id":"cef86354-9624-4487-9494-2cbb647e252a","metadata":{"id":"cef86354-9624-4487-9494-2cbb647e252a","outputId":"158845f5-e7a1-4e0d-f25e-2b1dfc285262"},"outputs":[{"name":"stdout","output_type":"stream","text":["Elapsed time: 5.7 seconds.\n","\n","Elapsed time: 5.62 seconds.\n","\n","Elapsed time: 5.59 seconds.\n","\n","5.64 s ± 44.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","test_build_by_apply(t_cat)"]},{"cell_type":"code","execution_count":null,"id":"88b4a8f7-eb98-41a0-a52c-3cf23b3987fd","metadata":{"id":"88b4a8f7-eb98-41a0-a52c-3cf23b3987fd","outputId":"050eea2b-81be-4449-d3ec-744e9d9deecc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Elapsed time: 2.44 seconds.\n","\n","Elapsed time: 2.4 seconds.\n","\n","Elapsed time: 2.41 seconds.\n","\n","2.41 s ± 18.4 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","test_build_by_itertuples(t_cat)"]},{"cell_type":"markdown","id":"feffabc4-06d9-47d1-ba2b-52c829e57e38","metadata":{"id":"feffabc4-06d9-47d1-ba2b-52c829e57e38"},"source":["It's clear that the itertuples method offers better (~ 2x) performace during this isolated stage, but what about the command execution stage?\n","\n","Here, we'll use the function(s) that combines the command creation and command execution steps and get averages run times for both methods.\n","\n","_Notes_:\n","1. Each iteration generates ~400,000 nodes so, we'll fully wipe the database between runs. This is fine for testing since we're only looking at relative performance rather than absolute. Alsi, the action is completed for both test cases so its impact can safely be ignored.\n","2. These tests were performed without the \"check for null Sentence ID\" step in the current `create_nodes` implementation. This was to ensure that there would be no notable discrepency between operational complexities of the two functions other than the underlying iteration method."]},{"cell_type":"code","execution_count":null,"id":"272c96bd-f907-4916-b512-aed9370f4b95","metadata":{"id":"272c96bd-f907-4916-b512-aed9370f4b95","outputId":"d007f605-ed52-45c3-99f7-41ccbb4647e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------PREDICATION------------------------------\n","\t23:54:32\tBuilding commands... \n","\t23:54:38\tCommand building complete. \n","\t23:54:38\tAttempting to execute commands... \n","\t01:08:01\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4409.08 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t01:08:07\tBuilding commands... \n","\t01:08:13\tCommand building complete. \n","\t01:08:13\tAttempting to execute commands... \n","\t02:24:06\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4559.33 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t02:24:11\tBuilding commands... \n","\t02:24:17\tCommand building complete. \n","\t02:24:17\tAttempting to execute commands... \n","\t03:40:30\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4578.06 seconds.\n","\n","1h 15min 19s ± 1min 15s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","create_nodes(t_cat)\n","\n","# clear nodes\n","driver.delete_data()"]},{"cell_type":"code","execution_count":null,"id":"d9e87864-e217-4c47-bcd3-0082593297d9","metadata":{"id":"d9e87864-e217-4c47-bcd3-0082593297d9","outputId":"679f7d5d-3bb7-4376-8eea-389216c66c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------PREDICATION------------------------------\n","\t03:40:34\tBuilding and executing commands... \n","\t04:56:33\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4558.82 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t04:56:39\tBuilding and executing commands... \n","\t06:12:42\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4563.26 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t06:12:47\tBuilding and executing commands... \n","\t07:28:56\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 4568.75 seconds.\n","\n","1h 16min 7s ± 4.28 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","create_nodes_by_itertuples(t_cat)\n","\n","# clear nodes\n","driver.delete_data()"]},{"cell_type":"markdown","id":"3e81944e-9d96-4bf3-af0f-30fcd0b7df37","metadata":{"id":"3e81944e-9d96-4bf3-af0f-30fcd0b7df37"},"source":["Interestingly, the itertuples method still offers comparable performance.\n","\n","Let's run the same test again using a larger (~12x) dataset and see how the two methods compare."]},{"cell_type":"code","execution_count":null,"id":"da45d8b0-f015-49b9-9bba-892ea426ea29","metadata":{"id":"da45d8b0-f015-49b9-9bba-892ea426ea29"},"outputs":[],"source":["data[t_cat] = data[temp].partitions[0:12]"]},{"cell_type":"code","execution_count":null,"id":"eb414173-3b7d-486b-aa16-a3e91ce36cec","metadata":{"id":"eb414173-3b7d-486b-aa16-a3e91ce36cec","outputId":"dd7d73a3-131b-420b-d824-562f1462dd0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Elapsed time: 68.61 seconds.\n","\n","Elapsed time: 67.87 seconds.\n","\n","Elapsed time: 68.16 seconds.\n","\n","1min 8s ± 304 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","test_build_by_apply(t_cat)"]},{"cell_type":"code","execution_count":null,"id":"bd4f635d-0adb-4af0-a6bd-df9fedd73772","metadata":{"id":"bd4f635d-0adb-4af0-a6bd-df9fedd73772","outputId":"352693e5-9929-4208-ea6a-154e85fe542c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Elapsed time: 29.26 seconds.\n","\n","Elapsed time: 29.21 seconds.\n","\n","Elapsed time: 29.28 seconds.\n","\n","29.2 s ± 29.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","test_build_by_itertuples(t_cat)\n"]},{"cell_type":"code","execution_count":null,"id":"9c4b8076-b4c0-4288-9877-43dd1767240e","metadata":{"id":"9c4b8076-b4c0-4288-9877-43dd1767240e","outputId":"a5318aa5-a270-4e0f-df54-6b51fbeafce7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------PREDICATION------------------------------\n","\t13:27:48\tBuilding commands... \n","\t13:28:57\tCommand building complete. \n","\t13:28:57\tAttempting to execute commands... \n","\t15:43:43\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 8155.02 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t15:45:46\tBuilding commands... \n","\t15:46:54\tCommand building complete. \n","\t15:46:54\tAttempting to execute commands... \n","\t18:00:54\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 8108.19 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t18:03:00\tBuilding commands... \n","\t18:04:08\tCommand building complete. \n","\t18:04:08\tAttempting to execute commands... \n","\t20:18:39\tCommand execution complete. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 8138.49 seconds.\n","\n","2h 16min 18s ± 18.5 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","batch_size = 200000\n","generated = 5000000\n","# creates about 5 million nodes in database.\n","create_nodes(t_cat)\n","\n","# clear nodes. Attempting to delete all nodes at once may crash server so delete in portions.\n","driver.delete_data(batch_size, math.ceil(generated/batch_size))"]},{"cell_type":"code","execution_count":null,"id":"d97b3ab1-bdf8-44ad-8f0c-1f288e68d833","metadata":{"id":"d97b3ab1-bdf8-44ad-8f0c-1f288e68d833","outputId":"0faed4eb-bcac-4bd6-bc63-fa92fe58fd75"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------------------------------PREDICATION------------------------------\n","\t20:20:43\tBuilding and executing commands... \n","\t10:43:50\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 51786.79 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t10:45:51\tBuilding and executing commands... \n","\t01:23:06\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 51723.85 seconds.\n","\n","\n","------------------------------PREDICATION------------------------------\n","\t01:25:07\tBuilding and executing commands... \n","\t15:50:13\tBuild and execution completed. \n","\n","Failed Command Creations: 0\n","Failed Command Executions: 0\n","Elapsed time: 51906.18 seconds.\n","\n","14h 24min 10s ± 1min 15s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"]}],"source":["%%timeit -n 1 -r 3\n","\n","create_nodes_by_itertuples(t_cat)\n","\n","# clear nodes. Attempting to delete all nodes at once may crash server so delete in portions.\n","driver.delete_data(batch_size, int(generated/batch_size))"]},{"cell_type":"markdown","id":"f8f9c1ac-4805-4120-8ae6-4b3596cc81de","metadata":{"id":"f8f9c1ac-4805-4120-8ae6-4b3596cc81de"},"source":["Annnnd what a letdown...\n","\n","While the itertuples method offered comparable, sometimes better, performance than the apply method with small datasets, it greatly suffered in performance with large datasets. This is because the itertuples method iterates through a dask dataframe linearly; in other words, with no optimizations. Whether split across multiple files or a single file, the itertuples method treats the dataframe as a gigantic list and accesses its data items one after another. Meanwhile, the apply method will parallelize the operations base with respect to each file leading to significant reduced downtime between node commands being executed.\n","\n","This is a great example of why performance testing is required in many scenarios. While one method of accomplishing a task may seem faster in one scenario, it can lead to serious performance drops in other scenario."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}